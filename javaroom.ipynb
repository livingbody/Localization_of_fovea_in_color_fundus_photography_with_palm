{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  飞桨常规赛：PALM眼底彩照中黄斑中央凹定位比赛 5月第5名方案\n",
    "比赛链接： [常规赛：PALM眼底彩照中黄斑中央凹定位](https://aistudio.baidu.com/aistudio/competition/detail/86)\n",
    "\n",
    "**github链接： [https://github.com/livingbody/Localization_of_fovea_in_color_fundus_photography_with_palm](https://github.com/livingbody/Localization_of_fovea_in_color_fundus_photography_with_palm)**\n",
    "\n",
    "**aistudio链接： [https://aistudio.baidu.com/aistudio/projectdetail/2027101](https://aistudio.baidu.com/aistudio/projectdetail/2027101)**\n",
    "\n",
    "## 0.0赛题介绍\n",
    "PALM黄斑定位常规赛的重点是研究和发展与患者眼底照片黄斑结构定位相关的算法。该常规赛的目标是评估和比较在一个常见的视网膜眼底图像数据集上定位黄斑的自动算法。具体目的是预测黄斑中央凹在图像中的坐标值。\n",
    "\n",
    "![](https://ai.bdstatic.com/file/D80ACC7A393348DD9F30518D57781D32)\n",
    "\n",
    "## 0.1数据简介\n",
    "PALM病理性近视预测常规赛由中山大学中山眼科中心提供800张带黄斑中央凹坐标标注的眼底彩照供选手训练模型，另提供400张带标注数据供平台进行模型测试。\n",
    "\n",
    "## 0.2数据说明\n",
    "本次常规赛提供的金标准由中山大学中山眼科中心的7名眼科医生手工进行标注，之后由另一位高级专家将它们融合为最终的标注结果。本比赛提供数据集对应的黄斑中央凹坐标信息存储在xlsx文件中，名为“Fovea_Location_train”，第一列对应眼底图像的文件名(包括扩展名“.jpg”)，第二列包含x坐标，第三列包含y坐标。\n",
    "\n",
    "![](https://ai.bdstatic.com/file/1CD1DA54E68349CA8553678E80F4D40E)\n",
    "\n",
    "## 0.3训练数据集\n",
    "文件名称：Train\n",
    "Train文件夹里有一个文件夹fundus_images和一个xlsx文件。\n",
    "\n",
    "fundus_images文件夹内包含800张眼底彩照，分辨率为1444×1444，或2124×2056。命名形如H0001.jpg、P0001.jpg、N0001.jpg和V0001.jpg。\n",
    "xlsx文件中包含800张眼底彩照对应的x、y坐标信息。\n",
    "## 0.4测试数据集\n",
    "文件名称：PALM-Testing400-Images 文件夹里包含400张眼底彩照，命名形如T0001.jpg。\n",
    "\n",
    "## 0.5提交格式\n",
    "黄斑中央凹定位比赛的提交内容需将所有测试图像的黄斑坐标存入一个CSV文件，名为“Fovea_Localization_Results.csv”，第一列对应测试眼底图像的文件名(包括扩展名“.jpg”)，第二列包含x坐标，第三列包含y坐标。\n",
    "\n",
    "![](https://ai.bdstatic.com/file/0D28C4FD24CA47748B867579C9A4CABC)\n",
    "\n",
    "## 0.6思路\n",
    "训练数据为图片以及中心点，要想从这些数据中推测测试数据中心店位置信息。可认为构造bbox，然后按目标检测来做，预测新的bbox，然后利用bbox来计算中心点，达到所需信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1.数据格式调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -aqo data/data85130/常规赛：PALM眼底彩照中黄斑中央凹定位.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm _* -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mv '常规赛：PALM眼底彩照中黄斑中央凹定位' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mv  dataset/Train/fundus_image  dataset/Train/JPEGImages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data=pd.read_excel('dataset/Train/Fovea_Location_train.xlsx')\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.1 自定义生成VOC数据集格式函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lxml操作需要用到\r\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml.etree import Element, SubElement, tostring\r\n",
    "from xml.dom.minidom import parseString\r\n",
    "import os\r\n",
    "\r\n",
    "\r\n",
    "def save_xml(image_name, bbox, save_dir='Annotations', width=10, height=10, channel=3):\r\n",
    "    '''\r\n",
    "    将CSV中的一行\r\n",
    "    000000001.jpg [[1,2,3,4],...]\r\n",
    "    转化成\r\n",
    "    000000001.xml\r\n",
    "\r\n",
    "    :param image_name:图片名\r\n",
    "    :param bbox:对应的bbox\r\n",
    "    :param save_dir:\r\n",
    "    :param width:这个是图片的宽度，博主使用的数据集是固定的大小的，所以设置默认\r\n",
    "    :param height:这个是图片的高度，博主使用的数据集是固定的大小的，所以设置默认\r\n",
    "    :param channel:这个是图片的通道，博主使用的数据集是固定的大小的，所以设置默认\r\n",
    "    :return:\r\n",
    "    '''\r\n",
    "\r\n",
    "    # 图片存放位置\r\n",
    "    node_root = Element('annotation')\r\n",
    "    node_folder = SubElement(node_root, 'folder')\r\n",
    "    node_folder.text = 'JPEGImages'\r\n",
    "\r\n",
    "    # 文件名\r\n",
    "    node_filename = SubElement(node_root, 'filename')\r\n",
    "    node_filename.text = os.path.join('JPEGImages',image_name.split('/')[-1])\r\n",
    "\r\n",
    "    # 文件长\r\n",
    "    node_size = SubElement(node_root, 'size')\r\n",
    "    node_width = SubElement(node_size, 'width')\r\n",
    "    node_width.text = '%s' % width\r\n",
    "\r\n",
    "    # 文件高\r\n",
    "    node_height = SubElement(node_size, 'height')\r\n",
    "    node_height.text = '%s' % height\r\n",
    "\r\n",
    "    # 文件通道\r\n",
    "    node_depth = SubElement(node_size, 'depth')\r\n",
    "    node_depth.text = '%s' % channel\r\n",
    "\r\n",
    "    # bbox\r\n",
    "    for x, y, w, h in bbox:\r\n",
    "        print(x, y, w, h)\r\n",
    "        left, top, right, bottom = x, y, x + w, y + h\r\n",
    "        node_object = SubElement(node_root, 'object')\r\n",
    "        node_name = SubElement(node_object, 'name')\r\n",
    "        node_name.text = 'bad'\r\n",
    "        node_difficult = SubElement(node_object, 'difficult')\r\n",
    "        node_difficult.text = '0'\r\n",
    "        node_bndbox = SubElement(node_object, 'bndbox')\r\n",
    "        node_xmin = SubElement(node_bndbox, 'xmin')\r\n",
    "        node_xmin.text = '%s' % left\r\n",
    "        node_ymin = SubElement(node_bndbox, 'ymin')\r\n",
    "        node_ymin.text = '%s' % top\r\n",
    "        node_xmax = SubElement(node_bndbox, 'xmax')\r\n",
    "        node_xmax.text = '%s' % right\r\n",
    "        node_ymax = SubElement(node_bndbox, 'ymax')\r\n",
    "        node_ymax.text = '%s' % bottom\r\n",
    "\r\n",
    "    xml = tostring(node_root, pretty_print=True)\r\n",
    "    dom = parseString(xml)\r\n",
    "\r\n",
    "    # 保存xml\r\n",
    "    image_name=image_name.split('/')[-1]\r\n",
    "    save_xml = os.path.join(save_dir, image_name.replace('jpg', 'xml'))\r\n",
    "    with open(save_xml, 'wb') as f:\r\n",
    "        f.write(xml)\r\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.2 开始生成voc格式xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "train_base_path='dataset/Train'\n",
    "# for i in range(10):\n",
    "for i in range(len(train_data)):\n",
    "    x=train_data.values[i,1]\n",
    "    y=train_data.values[i,2]\n",
    "    bbox=[[float(x-5), float(y-20), 40, 40]]\n",
    "    # print(bbox)\n",
    "    image_name=os.path.join(train_base_path,'JPEGImages', train_data.values[i,0])\n",
    "    img=cv2.imread(image_name)\n",
    "    # 0--height, 1--widht, 2--channel\n",
    "    height, width, channel = img.shape\n",
    "    \n",
    "    save_xml(image_name, bbox, save_dir=os.path.join(train_base_path,'Annotations'), width=width, height=height, channel=channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2.paddlex安装配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.1 paddlex安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install paddlex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.2 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 分割训练集、测试集\r\n",
    "!paddlex --split_dataset --format VOC --dataset_dir dataset/Train --val_value 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3.paddlex数据集配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.1引入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\n",
    "\r\n",
    "import paddlex as pdx\r\n",
    "from paddlex.det import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2 Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义训练和验证时的transforms\r\n",
    "# API说明 https://paddlex.readthedocs.io/zh_CN/develop/apis/transforms/seg_transforms.html\r\n",
    "train_transforms = transforms.Compose([\r\n",
    "    transforms.RandomHorizontalFlip(),\r\n",
    "    transforms.Normalize(),\r\n",
    "    transforms.ResizeByShort(short_size=800, max_size=1333),\r\n",
    "    transforms.Padding(coarsest_stride=32)\r\n",
    "])\r\n",
    "\r\n",
    "eval_transforms = transforms.Compose([\r\n",
    "    transforms.Normalize(),\r\n",
    "    transforms.ResizeByShort(short_size=800, max_size=1333),\r\n",
    "    transforms.Padding(coarsest_stride=32),\r\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.3 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义训练和验证所用的数据集\r\n",
    "# API说明：https://paddlex.readthedocs.io/zh_CN/develop/apis/datasets.html#paddlex-datasets-changedetdataset\r\n",
    "train_dataset = pdx.datasets.VOCDetection(\r\n",
    "    data_dir='dataset/Train',\r\n",
    "    file_list='dataset/Train/train_list.txt',\r\n",
    "    label_list='dataset/Train/labels.txt',\r\n",
    "    transforms=train_transforms,\r\n",
    "    shuffle=True)\r\n",
    "eval_dataset = pdx.datasets.VOCDetection(\r\n",
    "    data_dir='dataset/Train',\r\n",
    "    file_list='dataset/Train/val_list.txt',\r\n",
    "    label_list='dataset/Train/labels.txt',\r\n",
    "    transforms=eval_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.4 模型调用\r\n",
    "注意不同模型，背景是否也算作一类，也是有说法的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 初始化模型，并进行训练\r\n",
    "# 可使用VisualDL查看训练指标，参考https://paddlex.readthedocs.io/zh_CN/develop/train/visualdl.html\r\n",
    "num_classes = len(train_dataset.labels) + 1\r\n",
    "\r\n",
    "\r\n",
    "# API说明: https://paddlex.readthedocs.io/zh_CN/develop/apis/models/detection.html#paddlex-det-yolov3\r\n",
    "model = pdx.det.FasterRCNN(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4.开始训练\n",
    "我也很无语，40*40的框，就这么点精度\n",
    "\n",
    "```\n",
    "2021-05-26 20:39:03 [INFO]\t[EVAL] Finished, Epoch=17, bbox_map=0.002684 .\n",
    "2021-05-26 20:39:07 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_17.\n",
    "2021-05-26 20:39:07 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_8, bbox_map=4.625950541327286\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# API说明: https://paddlex.readthedocs.io/zh_CN/develop/apis/models/detection.html#id1\r\n",
    "# 各参数介绍与调整说明：https://paddlex.readthedocs.io/zh_CN/develop/appendix/parameters.html\r\n",
    "model.train(\r\n",
    "    num_epochs=100,\r\n",
    "    train_dataset=train_dataset,\r\n",
    "    train_batch_size=26,\r\n",
    "    eval_dataset=eval_dataset,\r\n",
    "    learning_rate=0.01,\r\n",
    "    lr_decay_epochs=[210, 240],\r\n",
    "    save_dir='output/faster_rcnn_r50_fpn',    \r\n",
    "    use_vdl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 5.模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.1 先预测一张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddlex as pdx\r\n",
    "model = pdx.load_model('output/faster_rcnn_r50_fpn/best_model')\r\n",
    "image_name = 'dataset/PALM-Testing400-Images/T0001.jpg'\r\n",
    "result = model.predict(image_name)\r\n",
    "print(result)\r\n",
    "pdx.det.visualize(image_name, result, threshold=0.5, save_dir='./output/faster_rcnn_r50_fpn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbox=result[0]['bbox']\r\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.2 生成文件名列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 预测数据集val_list\r\n",
    "val_list=[]\r\n",
    "for i in range(1,401,1):\r\n",
    "    filename='T'+ str(i).zfill(4)+'.jpg'\r\n",
    "    # print(filename)\r\n",
    "    val_list.append(filename+'\\n')\r\n",
    "\r\n",
    "with open('val_list.txt','w') as f:\r\n",
    "    f.writelines(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_A=[]\r\n",
    "with open('val_list.txt', 'r') as f:\r\n",
    "    for line in f:\r\n",
    "        line='dataset/PALM-Testing400-Images/'+line\r\n",
    "        pd_A.append(line.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.3预测并生成x/y坐标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddlex as pdx\r\n",
    "\r\n",
    "model = pdx.load_model('output/faster_rcnn_r50_fpn/best_model')\r\n",
    "# x坐标\r\n",
    "pd_B=[]\r\n",
    "# y坐标\r\n",
    "pd_C=[]\r\n",
    "for item in pd_A :\r\n",
    "    result = model.predict(item)\r\n",
    "    if  result:\r\n",
    "        bbox=result[0]['bbox']\r\n",
    "        x0=bbox[0]\r\n",
    "        x1=bbox[2]\r\n",
    "        y0=bbox[1]\r\n",
    "        y1=bbox[3]\r\n",
    "        x=0.5*(x1+x0)\r\n",
    "        y=0.5*(y1+y0)\r\n",
    "    else:\r\n",
    "        x=0\r\n",
    "        y=0\r\n",
    "    pd_B.append(x)\r\n",
    "    pd_C.append(y)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.4 构造pandas framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 文件名列\r\n",
    "pd_A=[]\r\n",
    "with open('val_list.txt', 'r') as f:\r\n",
    "    for line in f:\r\n",
    "        pd_A.append(line.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 构造pandas的DataFrame\r\n",
    "df= pd.DataFrame({'FileName': pd_A, 'Fovea_x':pd_B, 'Fovea_y':pd_C})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.5 保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存为提交文件\r\n",
    "df.to_csv(\"Fovea_Localization_Results.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取检查下\r\n",
    "data=pd.read_csv('Fovea_Localization_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看下生成数据\r\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 6.提交结果\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7a8e9138690047d7b021e99d91fa633eff9a8e76e157476bb4ef91fa64c67989)\n",
    "\n",
    "## 6.1 一个是要注意分割类别，不同模型是否要加背景，需要特别注意\n",
    "## 6.2 框的大小选择需要慎重，需要切合实际\n",
    "## 6.3 框的大小后来测试80左右最佳\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
